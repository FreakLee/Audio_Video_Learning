学习音视频开发，先复习一些相关的前置知识。

## 声音

[声音](https://zh.wikipedia.org/wiki/%E5%A3%B0%E9%9F%B3)是振动产生的声波，通过介质（气体、固体、液体）传播并能被人或动物听觉器官所感知的波动现象。

声音的频率一般会以赫兹表示，记为Hz，指每秒钟周期性震动的次数。而分贝是用来表示声音强度的单位，记为dB。

### 声音的产生

声音的产生源于物体的震动。当物体振动时，它会通过分子之间的相互作用传递能量，导致周围介质（如空气）中的分子也开始振动。这种物质中的振动以波的形式传播，被称为机械波。

物体振动的方式和频率决定了声音的特性。例如，弦乐器的弦线振动产生的声音频率取决于弦的长度、张力和质量。人的声音则是由声带的振动产生的，声带的紧张程度和振动频率决定了发出的声音音高的高低。

### 声音的传播

声音通过物质中的分子之间的相互作用以波的形式传播。在空气中，当物体振动时，它会使周围空气分子产生压缩和稀疏的变化，形成纵波。这些压缩和稀疏的区域以波的形式向外传播，传递声音的能量。

声音波在传播过程中具有以下特性：

* **频率（Frequency）**：声音波的频率决定了声音的音调，即高低音。频率以赫兹（Hz）为单位，表示每秒振动周期的数量。频率越大，音调越高；频率越小，音调越低。
* **振幅（Amplitude）**：声音波的振幅决定了声音的音量，即响度。振幅越大，音量（响度）越大；振幅越小，音量越小。
* **波长（Wavelength）**：声音波的波长是指一个完整波形的长度。波长与频率之间存在反比关系，波长越短，频率越高。

声音波可以在空气以外的其他介质中传播，如水、固体等。不同介质对声音的传播速度有影响，例如，声音在固体中的传播速度要比在气体中的传播速度更快。

### 声音的感知：

当声音波传播到我们的耳朵时，它们会引起耳膜振动。耳膜的振动将声音能量转化为机械能，并通过耳朵内部的结构传递给听觉神经系统。

耳朵内部包括耳道、鼓膜、中耳骨（锤骨、砧骨和镫骨）和内耳。鼓膜的振动将声音信号传递给中耳骨，中耳骨的振动进一步放大声音信号，并将其传递到内耳。

内耳中的蜗轮包含听觉感受器，称为毛细胞。当声音信号到达蜗轮时，它会引起毛细胞内的细小结构（纤毛）的震动。这些震动通过听觉神经传递给大脑的听觉皮层，然后被解码为我们能够感知的声音。

总结起来，声音的产生源于物体的振动，通过物质中分子之间的相互作用以波的形式传播。声音波在传播过程中具有频率、振幅和波长等特性。当声音波到达耳朵时，它们引起耳膜和内耳中的结构的振动，进而激活听觉感受器，将声音信号转化为神经信号传递给大脑，最终我们能够感知和理解声音。

## 音频

音频（Audio）是指通过声波传播来传递信息的形式。当我们听到声音时，实际上是在感知空气中的压力波动。音频可以包括音乐、语音、环境音效等。

### 基本原理

音频的生成是通过将声音转换成电信号来实现的。即音频数字化，将模拟信号转化为数字信号的过程。声音属于模拟信号，为了方便计算机存储和处理这些信号，需要将其转为数字信号。音频的采样、编码和解码是实现音频数字化的关键步骤。

### 采样（Sampling）

[采样](https://zh.wikipedia.org/wiki/%E5%8F%96%E6%A8%A3)是将信号从连续时间域上的模拟信号转换到离散时间域上的离散信号的过程。这个过程基于奈奎斯特-香农采样定理，该定理指出：为了准确地还原原始信号，采样率必须至少是信号最高频率的两倍。

具体的采样过程如下：

* 连续的声音信号首先通过麦克风或其他音频输入设备转换为模拟电信号。
* 模拟信号经过一个称为采样器的设备，以固定的时间间隔（采样周期）进行测量。
* 在每个采样周期内，采样器记录当前时刻的信号幅度，并将其转换为离散的数字值（采样值）。
* 采样率表示每秒采样的数据点数，常见的采样率有44.1kHz（CD音质）、48kHz（常用于音频和视频制作）等。

采样过程中，采样率的选择需要平衡音频质量和文件大小之间的关系。较高的采样率可以更准确地还原原始信号，但会增加数据量。

### 编码（Encoding）

采样后的音频数据需要进行编码，以便能够有效地存储和传输。音频编码的目标是在保持足够的音质的同时，尽可能减小文件大小。

常见的音频编码格式包括：

* MP3（MPEG Audio Layer III）：一种有损压缩格式，通过剔除人耳不易察觉的音频信号部分来减小文件大小。
* AAC（Advanced Audio Coding）：一种高级音频编码格式，与MP3相比，具有更好的音质和更高的压缩效率。
* WAV（Waveform Audio File Format）：一种无损的音频编码格式，保留了原始音频信号的所有信息，文件大小较大。

编码过程的具体步骤包括：

* 量化（Quantization）：将采样得到的连续数值转换为离散数值，以减小数据量。
* 压缩（Compression）：应用特定的压缩算法，根据音频信号的特性进一步减小数据量。
* 格式化（Formatting）：将编码后的数据按照特定的音频编码格式进行组织和存储。

### 解码（Decoding）

解码是将经过编码的音频数据还原为原始音频信号的过程。解码器根据编码格式的规范，对音频数据进行逆操作，以还原原始音频信号。

解码过程的具体步骤包括：

* 解析（Parsing）：解析编码文件的结构和元数据，以获取编码参数和音频描述信息。
* 解压缩（Decompression）：应用相应的解压缩算法，还原压缩过的音频数据。
* 逆量化（Dequantization）：将离散的音频数据转换为连续的数值。
* 重构（Reconstruction）：根据解码后的数据和采样率，重建连续的声音波形。

解码后的音频信号可以通过扬声器或耳机等设备进行播放，使我们能够听到原始的声音。

### 小结

音频的本质是通过声波传播来传递信息。声波是由震动的物体产生的机械波，它传播到我们的耳朵，通过耳膜和耳朵内部的结构转化为神经信号，最终由大脑解码成我们能够听到的声音。音频可以携带丰富的信息，包括声音的频率、幅度、时长等。

音频的采样、编码和解码是实现音频数字化的关键步骤。采样将连续的声音信号转换为离散的数据点，编码将采样后的数据进行压缩和格式化，解码将编码的音频数据还原为原始音频信号。这些步骤共同构成了音频数字化的过程，使得音频可以在数字设备上存储、传输和播放。

## 视频

视频（Video）是指通过连续的图像帧来传递信息的形式。它结合了图像和音频，可以呈现动态的场景。

### 基本原理

视频的生成是通过将连续的图像帧以特定的帧率快速播放来实现的。视频包括一系列静止的图像，每秒播放的图像数量称为帧率。常见的视频帧率包括24、30和60帧每秒。

视频的图像帧是通过摄像机或其他图像捕捉设备捕捉到的。这些图像经过压缩编码，以便能够有效地存储和传输。常见的视频编码格式包括MPEG-4、H.264、AVC等。

跟音频类似，视频的采样、编码和解码是数字视频处理的核心概念。

### 视频采样

视频采样是将连续的模拟视频信号转换为离散的数字形式。视频采样涉及两个主要方面：空间采样和时间采样。

* 空间采样：视频是由一系列图像（帧）组成的，每一帧都包含了图像中的空间信息。空间采样是将每一帧划分为一系列离散的像素点，并对每个像素点的亮度和颜色信息进行采样。

* 时间采样：视频中的连续帧之间存在时间上的关联。时间采样是在每一帧之间按照一定的时间间隔进行采样，以捕捉不同帧之间的动态变化。

### 视频编码

视频编码是将采样得到的数字视频数据进行压缩和编码，以便在存储和传输过程中减少数据量。视频编码的目标是在保持尽可能高的视觉质量的同时，尽量减少数据量。

常见的视频编码标准包括 MPEG（Moving Picture Experts Group）系列标准，如 MPEG-2、MPEG-4、H.264/AVC、H.265/HEVC 等。这些编码标准使用了一系列压缩算法和技术，包括以下关键概念：

* 空间域压缩：利用图像中的空间冗余性，即相邻像素之间的相关性，通过采样和预测算法来减少数据量。
* 时间域压缩：利用视频序列中的时间冗余性，即连续帧之间的相关性，通过帧间预测和差分编码来减少数据量。
* 变换编码：使用离散余弦变换（DCT）等变换方法将空间域的图像块转换为频域表示，从而利用频域的特性进一步减少数据量。
* 运动估计与补偿：通过对连续帧之间的运动进行估计，并将运动信息进行编码，以在解码端进行运动补偿，减少帧间的冗余信息。
* 熵编码：使用编码表和概率模型对视频数据进行编码，以减少数据的冗余性。常见的熵编码算法有霍夫曼编码和算术编码等。


#### H.264/AVC和H.265/HEVC的区别

H.264/AVC（Advanced Video Coding）和 H.265/HEVC（High Efficiency Video Coding）是两种常见的视频编码标准，它们在视频压缩和编码方面有以下主要区别：

* 压缩效率：
H.265/HEVC相较于H.264/AVC具有更高的压缩效率，即可以在保持相同视觉质量的情况下，显著减少数据量。HEVC采用了更先进的编码技术，如更强大的预测算法、更高效的变换编码和更优化的熵编码等，以提供更好的压缩性能。

* 码率控制：
H.265/HEVC引入了更多的码率控制方法，使得在特定目标比特率下，可以获得更好的视频质量。HEVC提供了更多的码率控制参数和算法选择，以适应不同应用场景下的需求。

* 分辨率和帧率支持：
H.265/HEVC相对于H.264/AVC具有更好的支持高分辨率和高帧率的能力。HEVC可以更有效地处理高清（HD）和超高清（UHD）视频，以及更高的帧率，如60帧/秒和120帧/秒。

* 并行处理和多核支持：
H.265/HEVC更好地利用了并行处理和多核处理器的优势，以提高编码和解码的效率。HEVC在算法设计上更注重并行计算和多核处理器的优化，以适应现代计算平台的发展。

尽管H.265/HEVC在压缩效率和性能方面具有明显优势，但它也需要更高的计算资源来进行编码和解码。相比之下，H.264/AVC在广泛应用和设备兼容性方面具有优势，尤其在旧一些的设备和传输网络中仍然被广泛支持和采用。

需要注意的是，由于H.264/AVC是较早的编码标准，而H.265/HEVC是其后续版本，因此H.265/HEVC编码器和解码器的处理复杂度更高，需要更先进的硬件支持。在实际应用中，选择使用哪种编码标准取决于具体的需求，包括视频质量、设备支持和网络带宽等因素。

### 视频解码：

视频解码是将编码后的数字视频数据恢复为原始的离散视频信号的过程。视频解码器使用与编码器相反的算法和技术，以逆转编码过程并还原视频数据。

解码过程包括以下步骤：

* 熵解码：使用相同的编码表和概率模型，对编码后的数据进行解码，以还原熵编码前的数据。
* 变换逆编码：对频域表示的图像块进行逆变换，将其转换回空间域表示，以恢复原始图像块。
* 运动补偿：使用解码器中的运动信息，对解码后的帧进行运动补偿，以还原原始帧。
* 帧内预测：对解码后的帧进行帧内预测，利用帧内的空间冗余性来减少数据量。
* 帧间预测和差分解码：通过解码器中的运动矢量和差分编码信息，对解码后的帧进行帧间预测和差分解码，以还原原始帧的动态变化。
* 重构：经过上述步骤后，得到解码后的离散视频信号，通过将连续的像素点重新组合成图像帧，最终得到还原的视频。

## 参考

[可汗学院声音的本质](https://www.khanacademy.org/science/high-school-physics/x2a2d643227022488:waves/introduction-to-sound/v/production-of-sound)

[维基百科声音](https://zh.wikipedia.org/wiki/%E5%A3%B0%E9%9F%B3)、音频、视频、采样等相关条目

[音频深度学习系列文章](https://towardsdatascience.com/audio-deep-learning-made-simple-part-1-state-of-the-art-techniques-da1d3dff2504)

[Huggingface Audio Course](https://huggingface.co/learn/audio-course)

[Analog to Digital Conversion, Sample Rate & Bit Depth](https://www.youtube.com/watch?v=Ov3GXhorrJE)
